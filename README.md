
# CodeLlama Multimodal Web UI

**CodeLlama Multimodal Web UI** is a user-friendly interface for interacting with the **Ollama** platformâ€™s **Llama 3.2 multimodal model**, which supports both **text** and **image** inputs. This versatile interface allows users to ask questions, submit prompts, and receive responses in the form of text, code, and even visual outputs, harnessing the power of **multimodal AI**.

## Features

- **Multimodal Input Support**: Submit both text and image inputs to receive context-aware responses.
- **Formatted Responses**: Highlighted code blocks and detailed explanations for code outputs.
- **Copy-to-Clipboard**: Easily copy code snippets directly from the UI for seamless integration into your projects.
- **Responsive UI**: Optimized for both desktop and mobile devices.
- **Interactive Output**: View text, images, and other media types generated by Llama 3.2.
- **Automatic Updates**: Automatically fetches updates from the repository when available.

## Installation

To run CodeLlama Multimodal Web UI locally, follow these steps:

1. **Clone the repository**:

    ``
    git clone https://github.com/iamgmujtaba/llama3.2-webUI
    ``

2. **Navigate to the project directory**:

    ``
    cd llama3.2-webUI
    ``

3. **Ensure PHP and Ollama are installed** on your machine:

    - Install PHP [here](https://www.php.net/downloads)
    - Install Ollama [here](https://ollama.com)

4. **Run the application** using the included shell script:

    ``
    bash run.sh
    ``

   This will start the local development server and automatically open the application in your default web browser at `http://localhost:8000`.

## Usage

### 1. Interacting with the UI

Once the interface loads in your browser, you can:

- **Submit Text Inputs**: Type your question or prompt in the input box and hit **Submit**.
- **Upload Images** (Coming soon): You will soon be able to upload images to receive both text and visual-based responses from the model.

### 2. Viewing Responses

- **Formatted Text**: Responses are displayed in a clean, readable format.
- **Highlighted Code**: Any code snippets returned are syntax-highlighted for better readability.
- **Multimodal Responses**: When image inputs are supported, you will also receive generated images, annotations, or detailed explanations of the content.

### 3. Copy Code to Clipboard

If the response contains code, you can click the **Copy** button to save the code snippet to your clipboard, making it easy to use in your own projects.

## Screenshots

### 1. **Prompt: "Hello World in C++"**
![homepage]()



## Contributing

We welcome contributions! If you have ideas for new features, improvements, or would like to report a bug, feel free to [create an issue](https://github.com/iamgmujtaba/llama3.2-webUI/issues) or submit a pull request.

### How to Contribute

1. **Fork the Repository**
2. **Create a New Branch** (`feature/amazing-feature`)
3. **Commit Your Changes** (`git commit -m 'Add some amazing feature'`)
4. **Push to the Branch** (`git push origin feature/amazing-feature`)
5. **Open a Pull Request**

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for more details.

## Acknowledgments
Feel free to improve this project by opening a pull request!
